{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29daf26-2aae-4127-a273-1fbf490b113c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-tune SantaCoder on YAML\n",
    "Sources:\n",
    "* https://github.com/loubnabnl/santacoder-finetuning\n",
    "* https://colab.research.google.com/drive/1UMjeXHwOldpLnWjdm1499o2IYy0RgeTw?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f655fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"transformers<4.41\" datasets ipywidgets torch\n",
    "! pip install accelerate -U\n",
    "! pip install bitsandbytes -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5f550-85d2-46dd-a80e-be899d17cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"1-train-yaml.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd30657-14b2-49f0-a84f-2adb1708efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case very detailed information is needed from the training phase\n",
    "# from transformers.utils import logging\n",
    "# logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3adb3c-ec83-4279-8ee2-040e7af94945",
   "metadata": {},
   "source": [
    "### Log in to HuggingFace to access The Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c37d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "# Note: Prefer notebook_login() but this was not prompting properly\n",
    "login(token=os.environ.get('HUGGINGFACE_TOKEN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc8eda-264c-43d1-9050-8a3184c1d11b",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    "    set_seed,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from dataset import ConstantLengthDataset\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b0ab4-798d-43f5-948c-6505fcd1252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BitsAndBytesConfig allows the configuration of the BitsAndBytes feature of Hugging Face Transformers.\n",
    "# This feature enables efficient model inference by reducing the model size and computational requirements.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                     # Enables loading the model in a 4-bit quantized format to reduce memory usage.\n",
    "    bnb_4bit_use_double_quant=True,        # Activates double quantization, which quantizes not just the weights but also the activations.\n",
    "    bnb_4bit_quant_type=\"nf4\",             # Sets the quantization type to 'nf4', a 4-bit number format for quantization.\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # Specifies bfloat16 as the data type for computation, balancing precision and speed.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea840e5f-d43d-4578-94f2-6145367d1710",
   "metadata": {},
   "source": [
    "### Specify the pre-trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bigcode/santacoder\"\n",
    "dataset_id = \"bigcode/the-stack-dedup\"\n",
    "data_dir = \"data/yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3348c67-027a-4da4-b76f-bbc83cde63ef",
   "metadata": {},
   "source": [
    "### Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fcc77-81a2-4aeb-ac48-9a9c3914be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e678c1-6891-49d8-a34f-43e0cbd26d50",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d92585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570e0bd-d2ed-42c3-a493-01dd247ea525",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Use the first 10% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id, data_dir=data_dir, split='train[:10%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0adcd-9c03-4498-898d-27e5d06ea5c8",
   "metadata": {},
   "source": [
    "### Calculate characters per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c27370",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, total_characters, total_tokens = 500, 0, 0\n",
    "\n",
    "for _, example in tqdm(zip(range(examples), iter(dataset)), total=examples):\n",
    "    total_characters += len(example['content'])\n",
    "    total_tokens += len(tokenizer(example['content']).tokens())\n",
    "\n",
    "characters_per_token = total_characters / total_tokens\n",
    "print(characters_per_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884c87e-45bb-468e-84b4-16e4cc2d8e4b",
   "metadata": {},
   "source": [
    "### Create a test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.005, shuffle=False, seed=555)\n",
    "train_ds = dataset[\"train\"]\n",
    "valid_ds = dataset[\"test\"]\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(seed=555)\n",
    "\n",
    "train_dataset = ConstantLengthDataset(\n",
    "        tokenizer, train_ds, infinite=True, seq_length=1024, chars_per_token=characters_per_token \n",
    "    )\n",
    "valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer, valid_ds, infinite=False, seq_length=1024, chars_per_token=characters_per_token\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f118f-f251-466d-bebb-2d5e62b01f14",
   "metadata": {},
   "source": [
    "### Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce427ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=\"santacoder-finetuned-the-stack-yaml\",\n",
    "        dataloader_drop_last=True,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"adafactor\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        # max_steps=5000,\n",
    "        # max_steps=1000,\n",
    "        # eval_steps=500,\n",
    "        # save_steps=500,\n",
    "        max_steps=100,\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        logging_steps=10,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        learning_rate=5e-5,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.05,\n",
    "        fp16=False,\n",
    "        push_to_hub=False,\n",
    "        logging_strategy='epoch',\n",
    "        # load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d5cca9-0e70-4bdf-bef5-c5d4c499ed5c",
   "metadata": {},
   "source": [
    "### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc683e-56e4-4453-9861-c5f29dc10375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e606c61a-6d06-45a7-899b-11c9e0af6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timezone = 'Europe/Brussels'\n",
    "\n",
    "class ETAProgressBarCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.total_steps = None\n",
    "        self.current_step = 0\n",
    "        self.average_step_duration = None\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        self.start_time = datetime.now(ZoneInfo(current_timezone))\n",
    "        self.total_steps = state.max_steps\n",
    "        \n",
    "        current_time = datetime.now(ZoneInfo(current_timezone))\n",
    "        str_current_time = current_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"Starting training at {str_current_time}\")\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.current_step += 1\n",
    "        current_time = datetime.now(ZoneInfo(current_timezone))\n",
    "        elapsed_time = current_time - self.start_time\n",
    "        self.average_step_duration = elapsed_time / self.current_step\n",
    "        estimated_total_time = self.average_step_duration * self.total_steps\n",
    "        \n",
    "        estimated_time_left = estimated_total_time - elapsed_time\n",
    "        days = estimated_time_left.days\n",
    "        hours, remainder = divmod(estimated_time_left.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        estimated_time_left_minutes_formatted = f\"{days}d {hours:02d}h:{minutes:02d}m:{seconds:02d}s\"\n",
    "        \n",
    "        estimated_end_time = (current_time + (estimated_total_time - elapsed_time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Calculate iterations per second\n",
    "        it_per_sec = self.current_step / (elapsed_time.days*3600*24 + elapsed_time.seconds)\n",
    "        # Access the current epoch from TrainerState\n",
    "        current_epoch = state.epoch\n",
    "        \n",
    "        print(f\"Step: {self.current_step}/{self.total_steps}, epoch: {current_epoch:.2f}, It/s: {it_per_sec:.2f}, est. time left: {estimated_time_left_minutes_formatted}, est. end time: {estimated_end_time}\")\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, model=None, metrics=None, **kwargs):\n",
    "        # Log evaluation metrics after every evaluation phase\n",
    "        if metrics:\n",
    "            print(\"Evaluation metrics:\")\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, model=None, **kwargs):\n",
    "        current_time = datetime.now(ZoneInfo(current_timezone))\n",
    "        str_current_time = current_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"Training completed at {str_current_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a735ff-9f84-4f5b-b859-6d9b48d25171",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.start_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d30bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    #tokenizer=tokenizer,\n",
    "    model=model, args=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[\n",
    "        # EarlyStoppingCallback(\n",
    "        #     early_stopping_patience=5,\n",
    "        #     early_stopping_threshold=1.0),\n",
    "        ETAProgressBarCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080edf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34854fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model() # this creates the config.json file etc you need to run generation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa5f6b-08fd-4665-b010-93034d98da02",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef48eb61-8645-4bea-b748-008426c43a8d",
   "metadata": {},
   "source": [
    "eval_res = trainer.evaluate()\n",
    "pprint.pprint(eval_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
